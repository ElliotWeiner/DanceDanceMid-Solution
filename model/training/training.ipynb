{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3d48c-c220-4d40-8993-ce08e676f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from FeetNet import FeetNet\n",
    "from dataloader import DDRDataset, getloaders\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def calculate_accuracy(model, testloader, device=None):\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct_predictions_l = 0\n",
    "    correct_predictions_r = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    # disable gradient calc\n",
    "    with torch.no_grad():\n",
    "        # iterate over testloader\n",
    "        for batch_idx, batch in enumerate(testloader):\n",
    "            # move data to the specified device\n",
    "            \n",
    "            #batch_in_image_1, batch_in_image_3, batch_gt_left, batch_gt_right = batch[0][0].to(device), batch[0][1].to(device), batch[1][0].to(device), batch[1][1].to(device)\n",
    "            batch_in_image_1, batch_in_image_3, batch_gt= batch[0][0].to(device), batch[0][1].to(device), batch[1].to(device)\n",
    "\n",
    "            # model predictions\n",
    "            #batch_out_left, batch_out_right = model(batch_in_image_1, batch_in_image_3)\n",
    "            #batch_out_left = torch.nn.functional.softmax(batch_out_left.squeeze(0), dim=1)\n",
    "            #batch_out_right = torch.nn.functional.softmax(batch_out_right.squeeze(0), dim=1)\n",
    "            \n",
    "            #batch_out = model(batch_in_image_1, batch_in_image_3)\n",
    "            batch_out = model(batch_in_image_1)\n",
    "\n",
    "            #print(batch_out.shape)\n",
    "            #batch_out = torch.nn.functional.softmax(batch_out, dim=1)\n",
    "            #print(batch_out_left.shape, batch_out_left)\n",
    "            #print(batch_out_right.shape, batch_out_right)\n",
    "\n",
    "            #print(batch_out, batch_gt)\n",
    "            \n",
    "            loss = criterion(batch_out, batch_gt)\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "            batch_out = torch.nn.functional.softmax(batch_out, dim=1)\n",
    "\n",
    "\n",
    "            # max index\n",
    "            #_, pr_l = torch.max(batch_out_left.data, 1)\n",
    "            #_, pr_r = torch.max(batch_out_right.data, 1)\n",
    "            #_, gt_l = torch.max(batch_gt_left.data, 1)\n",
    "            #_, gt_r = torch.max(batch_gt_right.data, 1)\n",
    "            \n",
    "            _, pr = torch.max(batch_out.data, 1)\n",
    "            _, gt = torch.max(batch_gt.data, 1)\n",
    "            \n",
    "            #pr = (pr == gt).long()\n",
    "            #gt = (gt == 10).long()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(\"pr, gt\")\n",
    "                print(pr)\n",
    "                print(gt)\n",
    "            \n",
    "            \n",
    "            #print(\"prl, gtl, prr, gtr\")\n",
    "            #print(pr_l.data)\n",
    "            #print(gt_l.data)\n",
    "            #print(pr_r.data)\n",
    "            #print(gt_r.data)\n",
    "            \n",
    "            #print(predicted_l.shape, batch_gt_left.shape)\n",
    "\n",
    "            # update total samples\n",
    "            #total_samples += batch_gt_right.size(0)\n",
    "            total_samples += batch_gt.size(0)\n",
    "\n",
    "            # Compare predicted classes with true labels\n",
    "            #correct_predictions_l += (pr_l == gt_l).sum().item()\n",
    "            #correct_predictions_r += (pr_r == gt_r).sum().item()\n",
    "            correct_predictions += (pr == gt).sum().item()\n",
    "            \n",
    "            print(correct_predictions, total_samples)\n",
    "            #print(correct_predictions_l, correct_predictions_r, total_samples)\n",
    "\n",
    "    total_val_loss = total_loss.cpu().detach().float()\n",
    "    total_val_loss /= 64\n",
    "    print(\"val loss: \",  total_val_loss)       \n",
    "    # calculate accuracy\n",
    "    #accuracy_l = 100 * correct_predictions_l / total_samples if total_samples > 0 else 0.0\n",
    "    #accuracy_r = 100 * correct_predictions_r / total_samples if total_samples > 0 else 0.0\n",
    "    accuracy_t = 100 * (correct_predictions) / total_samples if total_samples > 0 and total_samples > 0 else 0.0\n",
    "\n",
    "\t\n",
    "    return accuracy_t, total_val_loss#accuracy_l, accuracy_r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9deb9f-a2e5-4a36-94c8-aec285117467",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = getloaders(10000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d73458-db7c-45e2-8239-7d7e6de3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_feet(save_path, all_data, lr, num_povs):\n",
    "    \"\"\"\n",
    "    Function for training the network. You can make changes (e.g., add validation dataloader, change batch_size and #of epoch) accordingly.\n",
    "    \"\"\"\n",
    "\n",
    "    ######################################################################\n",
    "    # INIT\n",
    "    ######################################################################\n",
    "\n",
    "    print(\"Starting Training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    feet_net = FeetNet(num_povs).to(device)\n",
    "    #optimizer = torch.optim.Adam(feet_net.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.SGD(feet_net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    #scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=500)\n",
    "    scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=lr, max_lr=100*lr)\n",
    "    #criterion = torch.ops.sigmoid_focal_loss(\n",
    "    #loss_weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3]).to(device)\n",
    "    criterion1 = torch.nn.CrossEntropyLoss()\n",
    "    #criterion2 = torch.nn.CrossEntropyLoss(weight=loss_weights)\n",
    "\n",
    "    nr_epochs = 1000\n",
    "    batch_size = 64\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loader = all_data[0]\n",
    "    test_loader = all_data[1]\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # TRAINING LOOP - FOR EACH EPOCH\n",
    "    ######################################################################\n",
    "    print_interval = 5#int(len(train_loader)/batch_size)//2\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    l_losses = []\n",
    "    r_losses = []\n",
    "    acc_l = []\n",
    "    acc_r = []\n",
    "    acc = []\n",
    "    tr_acc_l = []\n",
    "    tr_acc_r = []\n",
    "    tr_acc = []\n",
    "    for epoch in range(nr_epochs):\n",
    "        total_loss_l = 0\n",
    "        total_loss_r = 0\n",
    "        total_loss = 0\n",
    "        batch_in = []\n",
    "        batch_gt = []\n",
    "\n",
    "\n",
    "        ######################################################################\n",
    "        # FOR EACH BATCH\n",
    "        ######################################################################\n",
    "\n",
    "        feet_net.train()\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # print(batch)\n",
    "            #batch_in_image_1, batch_in_image_3, batch_gt_left, batch_gt_right = batch[0][0].to(device), batch[0][1].to(device), batch[1][0].to(device), batch[1][1].to(device)\n",
    "            batch_in_image_1, batch_in_image_3, batch_gt = batch[0][0].to(device), batch[0][1].to(device), batch[1].to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            #test = batch_in_image_1[0].permute(1, 2, 0)\n",
    "            #print(test[:10, 60, 0])\n",
    "            #test = test.detach().cpu().clone()\n",
    "            #test *= 255.0\n",
    "            #test = test.byte()\n",
    "            #test = test.numpy()\n",
    "            #print(test.shape)\n",
    "            \n",
    "            #plt.imshow(test)\n",
    "            #plt.show()\n",
    "            #first_image = \n",
    "            \n",
    "\n",
    "            #batch_out_left, batch_out_right = feet_net(batch_in_image_1, batch_in_image_3)\n",
    "            \n",
    "            #batch_out = feet_net(batch_in_image_1, batch_in_image_3)\n",
    "            batch_out = feet_net(batch_in_image_1, batch_in_image_3)\n",
    "            print(batch_out[0])\n",
    "\n",
    "            \n",
    "\n",
    "            # print(batch_out_left.shape)\n",
    "            # print(batch_gt_left.shape)\n",
    "            # print(batch_gt_left, batch_out_left)\n",
    "            #batch_out_left = batch_out_left.squeeze(0)\n",
    "            #batch_out_right = batch_out_right.squeeze(0)\n",
    "            #loss_l = criterion1(batch_out_left, batch_gt_left)\n",
    "            #loss_r = criterion2(batch_out_right, batch_gt_right)\n",
    "            #loss_l = torchvision.ops.sigmoid_focal_loss(batch_out_left, batch_gt_left, reduction=\"sum\")\n",
    "            #loss_r = torchvision.ops.sigmoid_focal_loss(batch_out_right, batch_gt_right, reduction=\"sum\")\n",
    "            #loss = loss_l + loss_r\n",
    "            \n",
    "            #loss = torchvision.ops.sigmoid_focal_loss(batch_out, batch_gt, reduction=\"sum\")\n",
    "            loss = criterion1(batch_out, batch_gt)\n",
    "            \n",
    "            #print(loss)\n",
    "            loss = loss.squeeze(0)\n",
    "            #print(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #total_loss_l += loss_l\n",
    "            #total_loss_r += loss_r\n",
    "            total_loss += loss\n",
    "            # running_loss += loss\n",
    "\n",
    "            if batch_idx % print_interval == print_interval - 1:\n",
    "                last_loss = total_loss / print_interval # loss per batch\n",
    "                #last_ll = total_loss_l / print_interval\n",
    "                #last_lr = total_loss_r / print_interval\n",
    "                print('batch {} loss: {}'.format(batch_idx + 1, last_loss))#, last_ll, last_lr))\n",
    "                #print('batch {} loss: {}, ll: {}, lr: {}'.format(batch_idx + 1, last_loss, last_ll, last_lr))\n",
    "                total_loss = 0.\n",
    "                #total_loss_l = 0.\n",
    "                #total_loss_r = 0.\n",
    "        \n",
    "\n",
    "        ######################################################################\n",
    "        # STATISTICS\n",
    "        ######################################################################\n",
    "\n",
    "\n",
    "        time_per_epoch = (time.time() - start_time) / (epoch + 1)\n",
    "        time_left = (1.0 * time_per_epoch) * (nr_epochs - 1 - epoch)\n",
    "        lrBefore = optimizer.param_groups[0][\"lr\"]\n",
    "        scheduler.step()\n",
    "        lrAfter = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        #print(\"Epoch %5d\\t[Train]\\tloss: %.6f\\tloss_l: %.6f\\tloss_r: %.6f\\tlrb: %.8f\\tlra: %.8f \\tETA: +%fs\" % (\n",
    "        #    epoch + 1, last_loss, last_ll, last_lr, lrBefore, lrAfter, time_left))\n",
    "        print(\"Epoch %5d\\t[Train]\\tloss: %.6f\\tlrb: %.8f\\tlra: %.8f \\tETA: +%fs\" % (\n",
    "            epoch + 1, last_loss, lrBefore, lrAfter, time_left))\n",
    "        \n",
    "        #if epoch % 100 == 0 and epoch != 0:\n",
    "            #print(\"Saving Model Checkpoint\")\n",
    "            #torch.save(feet_net, save_path + str(epoch) + \"-feet_net.pth\")\n",
    "\n",
    "        \n",
    "        # check accuracy every 5 epochs\n",
    "        #feet_net.eval()\n",
    "        #if epoch % 5 == 0 and epoch != 0:\n",
    "        #test_accuracy_l, test_accuracy_r = calculate_accuracy(feet_net, test_loader, device)\n",
    "        #acc_l.append(test_accuracy_l)\n",
    "        #acc_r.append(test_accuracy_r)\n",
    "        #print(\"Test Accuracy L: %.6f\" % (test_accuracy_l))\n",
    "        #print(\"Test Accuracy R: %.6f\" % (test_accuracy_r))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if epoch % 5 == 0 and epoch != 0:\n",
    "        #    train_accuracy_l, train_accuracy_r = calculate_accuracy(feet_net, train_loader, device)\n",
    "        #    tr_acc_l.append(test_accuracy_l)\n",
    "        #    tr_acc_r.append(test_accuracy_r)\n",
    "        #    print(\"Train Accuracy L: %.6f\" % (train_accuracy_l))\n",
    "        #    print(\"Train Accuracy R: %.6f\" % (train_accuracy_r))\n",
    "\n",
    "\n",
    "        #l_losses.append(last_ll)\n",
    "        #r_losses.append(last_lr)\n",
    "        losses.append(last_loss)\n",
    "        \n",
    "        test_accuracy, test_loss = calculate_accuracy(feet_net, test_loader, device)\n",
    "        acc.append(test_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"Test Accuracy: %.6f\" % (test_accuracy))\n",
    "        if epoch % 5 == 0 and epoch != 0:\n",
    "            cpuLoss = [loss.cpu().detach().float() for loss in losses]\n",
    "            train_accuracy, train_loss = calculate_accuracy(feet_net, train_loader, device)\n",
    "            tr_acc.append(train_accuracy)\n",
    "            \n",
    "            print(\"Train Accuracy: %.6f\" % (train_accuracy))\n",
    "            \n",
    "            plt.figure()\n",
    "\n",
    "            epochs = list(range(0, len(cpuLoss), 1))\n",
    "            #print(epochs);\n",
    "            #print(cpuLoss);\n",
    "            tl = plt.plot(epochs, cpuLoss, label=\"Total Loss\")\n",
    "            ttl = plt.plot(epochs, test_losses, label=\"Total Test Loss\")\n",
    "            #ll = plt.plot(epochs, cpuLossL, label=\"L Loss\")\n",
    "            #rl = plt.plot(epochs, cpuLossR, label=\"R Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Losses\")\n",
    "            plt.title(\"Epoch vs Training Loss\")\n",
    "            plt.savefig('training_loss_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "\n",
    "            \n",
    "            epochs = list(range(0, len(tr_acc), 1))\n",
    "            epochs = [ 5 * epoch for epoch in epochs]\n",
    "            print(epochs);\n",
    "            print(tr_acc);\n",
    "            tl = plt.plot(epochs, tr_acc, label=\"Training Accuracy\")\n",
    "            \n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.title(\"Epoch vs Training Accuracy\")\n",
    "            plt.savefig('training_accuracy_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "    \n",
    "            epochs = list(range(0, len(acc), 1))\n",
    "            print(epochs);\n",
    "            print(acc);\n",
    "            tl = plt.plot(epochs, acc, label=\"Testing Accuracy\")\n",
    "            \n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.title(\"Epoch vs Testing Accuracy\")\n",
    "            plt.savefig('testing_accuracy_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "        if last_loss <= 0.00000000001:# or (last_ll <= 0.02 and last_lr <= 0.02):\n",
    "            #test_accuracy_l, test_accuracy_r = calculate_accuracy(feet_net, test_loader, device)\n",
    "            #acc_l.append(test_accuracy_l)\n",
    "            #acc_r.append(test_accuracy_r)\n",
    "            #print(\"Test Accuracy L: %.6f\" % (test_accuracy_l))\n",
    "            #print(\"Test Accuracy R: %.6f\" % (test_accuracy_r))\n",
    "            #train_accuracy_l, train_accuracy_r = calculate_accuracy(feet_net, train_loader, device)\n",
    "            #tr_acc_l.append(test_accuracy_l)\n",
    "            #tr_acc_r.append(test_accuracy_r)\n",
    "            #print(\"Train Accuracy L: %.6f\" % (train_accuracy_l))\n",
    "            #print(\"Train Accuracy R: %.6f\" % (train_accuracy_r))\n",
    "            test_accuracy = calculate_accuracy(feet_net, test_loader, device)\n",
    "            acc.append(test_accuracy)\n",
    "            print(\"Test Accuracy: %.6f\" % (test_accuracy))\n",
    "        \n",
    "            train_accuracy = calculate_accuracy(feet_net, train_loader, device)\n",
    "            tr_acc.append(test_accuracy)\n",
    "            print(\"Train Accuracy: %.6f\" % (train_accuracy))\n",
    "            break\n",
    "\n",
    "    \n",
    "    ######################################################################\n",
    "    # POST-TRAINING STATISTICS, PLOT & SAVE\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    print(\"Last loss: \", last_loss)\n",
    "    #print(\"Last_loss_l: \", last_ll)\n",
    "    #print(\"Last_loss_r: \", last_lr)\n",
    "\n",
    "    \n",
    "    cpuLoss = [loss.cpu().detach().float() for loss in losses]\n",
    "    #cpuLossL = [loss.cpu().detach().float() for loss in l_losses]\n",
    "    #cpuLossR = [loss.cpu().detach().float() for loss in r_losses]\n",
    "\n",
    "    plt.figure()\n",
    "    torch.save(feet_net, save_path + \"final_feet_net.pth\")\n",
    "    epochs = list(range(0, len(cpuLoss), 1))\n",
    "    print(epochs);\n",
    "    print(cpuLoss);\n",
    "    tl = plt.plot(epochs, cpuLoss, label=\"Total Loss\")\n",
    "    ttl = plt.plot(epochs, test_losses, label=\"Total Test Loss\")\n",
    "    #ll = plt.plot(epochs, cpuLossL, label=\"L Loss\")\n",
    "    #rl = plt.plot(epochs, cpuLossR, label=\"R Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.title(\"Epoch vs Loss\")\n",
    "    #plt.legend([tl, ll, rl])\n",
    "    plt.savefig('training_loss_class.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    epochs = list(range(0, len(tr_acc), 1))\n",
    "    epochs = [ 5 * epoch for epoch in epochs]\n",
    "    print(epochs);\n",
    "    print(tr_acc);\n",
    "    tl = plt.plot(epochs, tr_acc, label=\"Training Accuracy\")\n",
    "            \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Epoch vs Training Accuracy\")\n",
    "    plt.savefig('training_accuracy_class.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    epochs = list(range(0, len(acc), 1))\n",
    "    print(epochs);\n",
    "    print(acc);\n",
    "    tl = plt.plot(epochs, acc, label=\"Testing Accuracy\")\n",
    "            \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Epoch vs Testing Accuracy\")\n",
    "    plt.savefig('testing_accuracy_class.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec6a53-d0b0-4631-9dfc-ad4faa7735f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description='Feet Net Traininging')\n",
    "# parser.add_argument('-l', '--learning_rate', default=\"0.00001\", type=float, help='learning rate')\n",
    "# parser.add_argument('-s', '--save_path', default=\"./\", type=str, help='path where to save your model in .pth format')\n",
    "# parser.add_argument('-m', '--max_file', default=\"10000\", type=int, help='number of max file name')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# train_the_feet(args.save_path, args.learning_rate, 2, args.max_file)\n",
    "train_the_feet(\"./\", all_data, 0.0005, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13441768-4957-4036-a7e1-15efa9ce6fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09aeea-a8ec-4bed-b39c-fa10b6a33cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

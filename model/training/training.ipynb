{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d3d48c-c220-4d40-8993-ce08e676f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from FeetNet import FeetNet\n",
    "from dataloader import DDRDataset, getloaders\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def calculate_accuracy(model, testloader, device=None):\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct_predictions_l = 0\n",
    "    correct_predictions_r = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    # disable gradient calc\n",
    "    with torch.no_grad():\n",
    "        # iterate over testloader\n",
    "        for batch_idx, batch in enumerate(testloader):\n",
    "            # move data to the specified device\n",
    "            \n",
    "            #batch_in_image_1, batch_in_image_3, batch_gt_left, batch_gt_right = batch[0][0].to(device), batch[0][1].to(device), batch[1][0].to(device), batch[1][1].to(device)\n",
    "            batch_in_image_1, batch_in_image_3, batch_gt= batch[0][0].to(device), batch[0][1].to(device), batch[1].to(device)\n",
    "\n",
    "            # model predictions\n",
    "            #batch_out_left, batch_out_right = model(batch_in_image_1, batch_in_image_3)\n",
    "            #batch_out_left = torch.nn.functional.softmax(batch_out_left.squeeze(0), dim=1)\n",
    "            #batch_out_right = torch.nn.functional.softmax(batch_out_right.squeeze(0), dim=1)\n",
    "            \n",
    "            #batch_out = model(batch_in_image_1, batch_in_image_3)\n",
    "            batch_out = model(batch_in_image_1)\n",
    "\n",
    "            #print(batch_out.shape)\n",
    "            #batch_out = torch.nn.functional.softmax(batch_out, dim=1)\n",
    "            #print(batch_out_left.shape, batch_out_left)\n",
    "            #print(batch_out_right.shape, batch_out_right)\n",
    "\n",
    "            loss = criterion(batch_out, batch_gt)\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "            batch_out = torch.nn.functional.softmax(batch_out, dim=1)\n",
    "\n",
    "\n",
    "            # max index\n",
    "            #_, pr_l = torch.max(batch_out_left.data, 1)\n",
    "            #_, pr_r = torch.max(batch_out_right.data, 1)\n",
    "            #_, gt_l = torch.max(batch_gt_left.data, 1)\n",
    "            #_, gt_r = torch.max(batch_gt_right.data, 1)\n",
    "            \n",
    "            _, pr = torch.max(batch_out.data, 1)\n",
    "            _, gt = torch.max(batch_gt.data, 1)\n",
    "            \n",
    "            #pr = (pr == gt).long()\n",
    "            #gt = (gt == 10).long()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(\"pr, gt\")\n",
    "                print(pr)\n",
    "                print(gt)\n",
    "            \n",
    "            \n",
    "            #print(\"prl, gtl, prr, gtr\")\n",
    "            #print(pr_l.data)\n",
    "            #print(gt_l.data)\n",
    "            #print(pr_r.data)\n",
    "            #print(gt_r.data)\n",
    "            \n",
    "            #print(predicted_l.shape, batch_gt_left.shape)\n",
    "\n",
    "            # update total samples\n",
    "            #total_samples += batch_gt_right.size(0)\n",
    "            total_samples += batch_gt.size(0)\n",
    "\n",
    "            # Compare predicted classes with true labels\n",
    "            #correct_predictions_l += (pr_l == gt_l).sum().item()\n",
    "            #correct_predictions_r += (pr_r == gt_r).sum().item()\n",
    "            correct_predictions += (pr == gt).sum().item()\n",
    "            \n",
    "            print(correct_predictions, total_samples)\n",
    "            #print(correct_predictions_l, correct_predictions_r, total_samples)\n",
    "\n",
    "    total_val_loss = total_loss.cpu().detach().float()\n",
    "    total_val_loss /= 64\n",
    "    print(\"val loss: \",  total_val_loss)       \n",
    "    # calculate accuracy\n",
    "    #accuracy_l = 100 * correct_predictions_l / total_samples if total_samples > 0 else 0.0\n",
    "    #accuracy_r = 100 * correct_predictions_r / total_samples if total_samples > 0 else 0.0\n",
    "    accuracy_t = 100 * (correct_predictions) / total_samples if total_samples > 0 and total_samples > 0 else 0.0\n",
    "\n",
    "\t\n",
    "    return accuracy_t, total_val_loss#accuracy_l, accuracy_r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9deb9f-a2e5-4a36-94c8-aec285117467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24313 24313\n",
      "10238 10238\n",
      "{0: 1815, 1: 1740, 2: 1737, 3: 1931, 4: 1750, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n"
     ]
    }
   ],
   "source": [
    "all_data = getloaders(10000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d73458-db7c-45e2-8239-7d7e6de3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_feet(save_path, all_data, lr, num_povs):\n",
    "    \"\"\"\n",
    "    Function for training the network. You can make changes (e.g., add validation dataloader, change batch_size and #of epoch) accordingly.\n",
    "    \"\"\"\n",
    "\n",
    "    ######################################################################\n",
    "    # INIT\n",
    "    ######################################################################\n",
    "\n",
    "    print(\"Starting Training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    feet_net = FeetNet(num_povs).to(device)\n",
    "    #optimizer = torch.optim.Adam(feet_net.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.SGD(feet_net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    #scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=500)\n",
    "    scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=lr, max_lr=100*lr)\n",
    "    #criterion = torch.ops.sigmoid_focal_loss(\n",
    "    #loss_weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3]).to(device)\n",
    "    criterion1 = torch.nn.CrossEntropyLoss()\n",
    "    #criterion2 = torch.nn.CrossEntropyLoss(weight=loss_weights)\n",
    "\n",
    "    nr_epochs = 1000\n",
    "    batch_size = 64\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loader = all_data[0]\n",
    "    test_loader = all_data[1]\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # TRAINING LOOP - FOR EACH EPOCH\n",
    "    ######################################################################\n",
    "    print_interval = 5#int(len(train_loader)/batch_size)//2\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    l_losses = []\n",
    "    r_losses = []\n",
    "    acc_l = []\n",
    "    acc_r = []\n",
    "    acc = []\n",
    "    tr_acc_l = []\n",
    "    tr_acc_r = []\n",
    "    tr_acc = []\n",
    "    for epoch in range(nr_epochs):\n",
    "        total_loss_l = 0\n",
    "        total_loss_r = 0\n",
    "        total_loss = 0\n",
    "        batch_in = []\n",
    "        batch_gt = []\n",
    "\n",
    "\n",
    "        ######################################################################\n",
    "        # FOR EACH BATCH\n",
    "        ######################################################################\n",
    "\n",
    "        feet_net.train()\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # print(batch)\n",
    "            #batch_in_image_1, batch_in_image_3, batch_gt_left, batch_gt_right = batch[0][0].to(device), batch[0][1].to(device), batch[1][0].to(device), batch[1][1].to(device)\n",
    "            batch_in_image_1, batch_in_image_3, batch_gt = batch[0][0].to(device), batch[0][1].to(device), batch[1].to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            #test = batch_in_image_1[0].permute(1, 2, 0)\n",
    "            #print(test[:10, 60, 0])\n",
    "            #test = test.detach().cpu().clone()\n",
    "            #test *= 255.0\n",
    "            #test = test.byte()\n",
    "            #test = test.numpy()\n",
    "            #print(test.shape)\n",
    "            \n",
    "            #plt.imshow(test)\n",
    "            #plt.show()\n",
    "            #first_image = \n",
    "            \n",
    "\n",
    "            # print(batch_in_image_1.shape)\n",
    "            #batch_out_left, batch_out_right = feet_net(batch_in_image_1, batch_in_image_3)\n",
    "            \n",
    "            #batch_out = feet_net(batch_in_image_1, batch_in_image_3)\n",
    "            batch_out = feet_net(batch_in_image_1)\n",
    "\n",
    "            \n",
    "\n",
    "            # print(batch_out_left.shape)\n",
    "            # print(batch_gt_left.shape)\n",
    "            # print(batch_gt_left, batch_out_left)\n",
    "            #batch_out_left = batch_out_left.squeeze(0)\n",
    "            #batch_out_right = batch_out_right.squeeze(0)\n",
    "            #loss_l = criterion1(batch_out_left, batch_gt_left)\n",
    "            #loss_r = criterion2(batch_out_right, batch_gt_right)\n",
    "            #loss_l = torchvision.ops.sigmoid_focal_loss(batch_out_left, batch_gt_left, reduction=\"sum\")\n",
    "            #loss_r = torchvision.ops.sigmoid_focal_loss(batch_out_right, batch_gt_right, reduction=\"sum\")\n",
    "            #loss = loss_l + loss_r\n",
    "            \n",
    "            #loss = torchvision.ops.sigmoid_focal_loss(batch_out, batch_gt, reduction=\"sum\")\n",
    "            loss = criterion1(batch_out, batch_gt)\n",
    "            \n",
    "            #print(loss)\n",
    "            loss = loss.squeeze(0)\n",
    "            #print(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #total_loss_l += loss_l\n",
    "            #total_loss_r += loss_r\n",
    "            total_loss += loss\n",
    "            # running_loss += loss\n",
    "\n",
    "            if batch_idx % print_interval == print_interval - 1:\n",
    "                last_loss = total_loss / print_interval # loss per batch\n",
    "                #last_ll = total_loss_l / print_interval\n",
    "                #last_lr = total_loss_r / print_interval\n",
    "                print('batch {} loss: {}'.format(batch_idx + 1, last_loss))#, last_ll, last_lr))\n",
    "                #print('batch {} loss: {}, ll: {}, lr: {}'.format(batch_idx + 1, last_loss, last_ll, last_lr))\n",
    "                total_loss = 0.\n",
    "                #total_loss_l = 0.\n",
    "                #total_loss_r = 0.\n",
    "        \n",
    "\n",
    "        ######################################################################\n",
    "        # STATISTICS\n",
    "        ######################################################################\n",
    "\n",
    "\n",
    "        time_per_epoch = (time.time() - start_time) / (epoch + 1)\n",
    "        time_left = (1.0 * time_per_epoch) * (nr_epochs - 1 - epoch)\n",
    "        lrBefore = optimizer.param_groups[0][\"lr\"]\n",
    "        scheduler.step()\n",
    "        lrAfter = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        #print(\"Epoch %5d\\t[Train]\\tloss: %.6f\\tloss_l: %.6f\\tloss_r: %.6f\\tlrb: %.8f\\tlra: %.8f \\tETA: +%fs\" % (\n",
    "        #    epoch + 1, last_loss, last_ll, last_lr, lrBefore, lrAfter, time_left))\n",
    "        print(\"Epoch %5d\\t[Train]\\tloss: %.6f\\tlrb: %.8f\\tlra: %.8f \\tETA: +%fs\" % (\n",
    "            epoch + 1, last_loss, lrBefore, lrAfter, time_left))\n",
    "        \n",
    "        #if epoch % 100 == 0 and epoch != 0:\n",
    "            #print(\"Saving Model Checkpoint\")\n",
    "            #torch.save(feet_net, save_path + str(epoch) + \"-feet_net.pth\")\n",
    "\n",
    "        \n",
    "        # check accuracy every 5 epochs\n",
    "        #feet_net.eval()\n",
    "        #if epoch % 5 == 0 and epoch != 0:\n",
    "        #test_accuracy_l, test_accuracy_r = calculate_accuracy(feet_net, test_loader, device)\n",
    "        #acc_l.append(test_accuracy_l)\n",
    "        #acc_r.append(test_accuracy_r)\n",
    "        #print(\"Test Accuracy L: %.6f\" % (test_accuracy_l))\n",
    "        #print(\"Test Accuracy R: %.6f\" % (test_accuracy_r))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if epoch % 5 == 0 and epoch != 0:\n",
    "        #    train_accuracy_l, train_accuracy_r = calculate_accuracy(feet_net, train_loader, device)\n",
    "        #    tr_acc_l.append(test_accuracy_l)\n",
    "        #    tr_acc_r.append(test_accuracy_r)\n",
    "        #    print(\"Train Accuracy L: %.6f\" % (train_accuracy_l))\n",
    "        #    print(\"Train Accuracy R: %.6f\" % (train_accuracy_r))\n",
    "\n",
    "\n",
    "        #l_losses.append(last_ll)\n",
    "        #r_losses.append(last_lr)\n",
    "        losses.append(last_loss)\n",
    "        \n",
    "        test_accuracy, test_loss = calculate_accuracy(feet_net, test_loader, device)\n",
    "        acc.append(test_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"Test Accuracy: %.6f\" % (test_accuracy))\n",
    "        if epoch % 5 == 0 and epoch != 0:\n",
    "            cpuLoss = [loss.cpu().detach().float() for loss in losses]\n",
    "            train_accuracy, train_loss = calculate_accuracy(feet_net, train_loader, device)\n",
    "            tr_acc.append(train_accuracy)\n",
    "            \n",
    "            print(\"Train Accuracy: %.6f\" % (train_accuracy))\n",
    "            \n",
    "            plt.figure()\n",
    "\n",
    "            epochs = list(range(0, len(cpuLoss), 1))\n",
    "            #print(epochs);\n",
    "            #print(cpuLoss);\n",
    "            tl = plt.plot(epochs, cpuLoss, label=\"Total Loss\")\n",
    "            ttl = plt.plot(epochs, test_losses, label=\"Total Test Loss\")\n",
    "            #ll = plt.plot(epochs, cpuLossL, label=\"L Loss\")\n",
    "            #rl = plt.plot(epochs, cpuLossR, label=\"R Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Losses\")\n",
    "            plt.title(\"Epoch vs Training Loss\")\n",
    "            plt.savefig('training_loss_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "\n",
    "            \n",
    "            epochs = list(range(0, len(tr_acc), 1))\n",
    "            epochs = [ 5 * epoch for epoch in epochs]\n",
    "            print(epochs);\n",
    "            print(tr_acc);\n",
    "            tl = plt.plot(epochs, tr_acc, label=\"Training Accuracy\")\n",
    "            \n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.title(\"Epoch vs Training Accuracy\")\n",
    "            plt.savefig('training_accuracy_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "    \n",
    "            epochs = list(range(0, len(acc), 1))\n",
    "            print(epochs);\n",
    "            print(acc);\n",
    "            tl = plt.plot(epochs, acc, label=\"Testing Accuracy\")\n",
    "            \n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.title(\"Epoch vs Testing Accuracy\")\n",
    "            plt.savefig('testing_accuracy_class.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "        if last_loss <= 0.00000000001:# or (last_ll <= 0.02 and last_lr <= 0.02):\n",
    "            #test_accuracy_l, test_accuracy_r = calculate_accuracy(feet_net, test_loader, device)\n",
    "            #acc_l.append(test_accuracy_l)\n",
    "            #acc_r.append(test_accuracy_r)\n",
    "            #print(\"Test Accuracy L: %.6f\" % (test_accuracy_l))\n",
    "            #print(\"Test Accuracy R: %.6f\" % (test_accuracy_r))\n",
    "            #train_accuracy_l, train_accuracy_r = calculate_accuracy(feet_net, train_loader, device)\n",
    "            #tr_acc_l.append(test_accuracy_l)\n",
    "            #tr_acc_r.append(test_accuracy_r)\n",
    "            #print(\"Train Accuracy L: %.6f\" % (train_accuracy_l))\n",
    "            #print(\"Train Accuracy R: %.6f\" % (train_accuracy_r))\n",
    "            test_accuracy = calculate_accuracy(feet_net, test_loader, device)\n",
    "            acc.append(test_accuracy)\n",
    "            print(\"Test Accuracy: %.6f\" % (test_accuracy))\n",
    "        \n",
    "            train_accuracy = calculate_accuracy(feet_net, train_loader, device)\n",
    "            tr_acc.append(test_accuracy)\n",
    "            print(\"Train Accuracy: %.6f\" % (train_accuracy))\n",
    "            break\n",
    "\n",
    "    \n",
    "    ######################################################################\n",
    "    # POST-TRAINING STATISTICS, PLOT & SAVE\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    print(\"Last loss: \", last_loss)\n",
    "    #print(\"Last_loss_l: \", last_ll)\n",
    "    #print(\"Last_loss_r: \", last_lr)\n",
    "\n",
    "    \n",
    "    cpuLoss = [loss.cpu().detach().float() for loss in losses]\n",
    "    #cpuLossL = [loss.cpu().detach().float() for loss in l_losses]\n",
    "    #cpuLossR = [loss.cpu().detach().float() for loss in r_losses]\n",
    "\n",
    "    plt.figure()\n",
    "    torch.save(feet_net, save_path + \"final_feet_net.pth\")\n",
    "    epochs = list(range(0, len(cpuLoss), 1))\n",
    "    print(epochs);\n",
    "    print(cpuLoss);\n",
    "    tl = plt.plot(epochs, cpuLoss, label=\"Total Loss\")\n",
    "    ttl = plt.plot(epochs, test_losses, label=\"Total Test Loss\")\n",
    "    #ll = plt.plot(epochs, cpuLossL, label=\"L Loss\")\n",
    "    #rl = plt.plot(epochs, cpuLossR, label=\"R Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.title(\"Epoch vs Loss\")\n",
    "    #plt.legend([tl, ll, rl])\n",
    "    plt.savefig('training_loss_class.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    epochs = list(range(0, len(tr_acc), 1))\n",
    "    epochs = [ 5 * epoch for epoch in epochs]\n",
    "    print(epochs);\n",
    "    print(tr_acc);\n",
    "    tl = plt.plot(epochs, tr_acc, label=\"Training Accuracy\")\n",
    "            \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Epoch vs Training Accuracy\")\n",
    "    plt.savefig('training_accuracy_class.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    epochs = list(range(0, len(acc), 1))\n",
    "    print(epochs);\n",
    "    print(acc);\n",
    "    tl = plt.plot(epochs, acc, label=\"Testing Accuracy\")\n",
    "            \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Epoch vs Testing Accuracy\")\n",
    "    plt.savefig('testing_accuracy_class.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dec6a53-d0b0-4631-9dfc-ad4faa7735f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ec523/students/arwang/.conda/envs/ddr/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/projectnb/ec523/students/arwang/.conda/envs/ddr/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R2Plus1D_18_Weights.KINETICS400_V1`. You can also use `weights=R2Plus1D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FeetNet.forward() missing 1 required positional argument: 'v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# parser = argparse.ArgumentParser(description='Feet Net Traininging')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# parser.add_argument('-l', '--learning_rate', default=\"0.00001\", type=float, help='learning rate')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# parser.add_argument('-s', '--save_path', default=\"./\", type=str, help='path where to save your model in .pth format')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# train_the_feet(args.save_path, args.learning_rate, 2, args.max_file)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_the_feet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 84\u001b[0m, in \u001b[0;36mtrain_the_feet\u001b[0;34m(save_path, all_data, lr, num_povs)\u001b[0m\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#test = batch_in_image_1[0].permute(1, 2, 0)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(test[:10, 60, 0])\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#test = test.detach().cpu().clone()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#batch_out = feet_net(batch_in_image_1, batch_in_image_3)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m \u001b[43mfeet_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_in_image_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# print(batch_out_left.shape)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# print(batch_gt_left.shape)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# print(batch_gt_left, batch_out_left)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#loss = torchvision.ops.sigmoid_focal_loss(batch_out, batch_gt, reduction=\"sum\")\u001b[39;00m\n\u001b[1;32m    100\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion1(batch_out, batch_gt)\n",
      "File \u001b[0;32m/projectnb/ec523/students/arwang/.conda/envs/ddr/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ec523/students/arwang/.conda/envs/ddr/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: FeetNet.forward() missing 1 required positional argument: 'v2'"
     ]
    }
   ],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description='Feet Net Traininging')\n",
    "# parser.add_argument('-l', '--learning_rate', default=\"0.00001\", type=float, help='learning rate')\n",
    "# parser.add_argument('-s', '--save_path', default=\"./\", type=str, help='path where to save your model in .pth format')\n",
    "# parser.add_argument('-m', '--max_file', default=\"10000\", type=int, help='number of max file name')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# train_the_feet(args.save_path, args.learning_rate, 2, args.max_file)\n",
    "train_the_feet(\"./\", all_data, 0.0005, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13441768-4957-4036-a7e1-15efa9ce6fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09aeea-a8ec-4bed-b39c-fa10b6a33cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
